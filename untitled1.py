# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kpGg2hOnpNaJiMGei8IJs_ympJIeqTFX
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

from google.colab import files
files.upload()

from google.colab import files
files.upload()

!wget -O content.jpg https://upload.wikimedia.org/wikipedia/commons/6/6e/Golde33443.jpg

!wget -O style.jpg https://images.unsplash.com/photo-1518770660439-4636190af475

!file content.jpg
!file style.jpg

import tensorflow as tf

def load_img(path):
    img = tf.io.read_file(path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, (256, 256))
    img = tf.expand_dims(img, axis=0)
    img = tf.cast(img, tf.float32)
    return img

content_image = load_img("content.jpg")
style_image = load_img("style.jpg")

print(content_image.shape)
print(style_image.shape)

import matplotlib.pyplot as plt
import numpy as np

def show_image(img, title=""):
    # If float, normalize to [0,1]
    if img.dtype == np.float32 or img.dtype == np.float64:
        img = np.clip(img, 0, 255) / 255.0
    plt.imshow(img)
    plt.title(title)
    plt.axis("off")

plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
show_image(content_image[0], "Content Image")

plt.subplot(1,2,2)
show_image(style_image[0], "Style Image")

plt.show()

vgg = tf.keras.applications.VGG19(
    include_top=False,
    weights='imagenet'
)
vgg.trainable = False

content_layers = ['block5_conv2']
style_layers = [
    'block1_conv1',
    'block2_conv1',
    'block3_conv1',
    'block4_conv1',
    'block5_conv1'
]

def vgg_layers(layer_names):
    outputs = [vgg.get_layer(name).output for name in layer_names]
    return tf.keras.Model(vgg.input, outputs)

style_extractor = vgg_layers(style_layers)
content_extractor = vgg_layers(content_layers)

generated_image = tf.Variable(content_image, dtype=tf.float32)

def style_loss(style_outputs, style_targets):
    loss = 0
    for s, t in zip(style_outputs, style_targets):
        loss += tf.reduce_mean((s - t) ** 2)
    return loss

def content_loss(content_output, content_target):
    return tf.reduce_mean((content_output - content_target) ** 2)

optimizer = tf.optimizers.Adam(learning_rate=0.02)

style_targets = style_extractor(style_image)
content_target = content_extractor(content_image)[0]

for step in range(100):
    with tf.GradientTape() as tape:
        style_outputs = style_extractor(generated_image)
        content_output = content_extractor(generated_image)[0]

        s_loss = style_loss(style_outputs, style_targets)
        c_loss = content_loss(content_output, content_target)

        total_loss = s_loss + c_loss

    grads = tape.gradient(total_loss, generated_image)
    optimizer.apply_gradients([(grads, generated_image)])

    if step % 20 == 0:
        print(f"Step {step}, Loss: {total_loss.numpy():.2f}")

plt.figure(figsize=(6,6))
plt.title("Stylized Image")
plt.imshow(tf.clip_by_value(generated_image[0], 0, 255) / 255.0)
plt.axis("off")
plt.show()